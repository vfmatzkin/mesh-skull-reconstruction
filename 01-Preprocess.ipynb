{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Rigid registration and skull extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import expanduser as eu\n",
    "from headctools.registration import register_file_folder\n",
    "from headctools.preprocessing import ct_skull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import vtk\n",
    "\n",
    "def stl_to_vtk(filename):\n",
    "    # Read the .stl file \n",
    "    a = vtk.vtkSTLReader()\n",
    "    a.SetFileName(filename)\n",
    "    a.Update()\n",
    "    a = a.GetOutput()\n",
    "\n",
    "    # Write the .vtk file\n",
    "    filename = filename.replace('.stl', '.vtk')\n",
    "    b = vtk.vtkPolyDataWriter()\n",
    "    b.SetFileName(filename)\n",
    "    b.SetInputData(a)\n",
    "    b.Update()\n",
    "    return filename"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imgs = eu('~/Code/datasets/cq500/converted/selected/')\n",
    "fixed_img = os.path.join(imgs, 'CQ500-CT-312_CT PRE CONTRAST THIN.nii.gz')\n",
    "# Registered images will be saved in a sub folder with the name of the fixed image\n",
    "\n",
    "params = {\n",
    "    'reg_atlas_path': fixed_img\n",
    "}\n",
    "\n",
    "ct_skull(imgs, params = params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mesh atlas construction"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decimate meshes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import vedo\n",
    "\n",
    "print('Decimating meshes...')\n",
    "decimate_percent = 0.005\n",
    "\n",
    "meshes_folder = eu('~/Code/datasets/cq500/converted/selected/preprocessed_ct_to_skull/test')\n",
    "print( f'  Input folder: {meshes_folder}')\n",
    "meshes_paths = [os.path.join(meshes_folder, f) for f in os.listdir(meshes_folder) if f.endswith('.stl') and 'decimated' not in f]\n",
    "saved_meshes = []\n",
    "print(f'  Found {len(meshes_paths)} meshes')\n",
    "for i, mesh in enumerate(meshes_paths):\n",
    "    print(f'    [{i+1}/{len(meshes_paths)}] Input mesh: {os.path.split(mesh)[1]}')\n",
    "    v_mesh = vedo.Mesh(mesh).decimate(decimate_percent)\n",
    "    decimated_path = mesh.replace('.stl', f'_decimated_{int(decimate_percent*100)}perc_{v_mesh.points().shape[0]}points.stl')\n",
    "    v_mesh.write(decimated_path)\n",
    "    saved_meshes.append(decimated_path)\n",
    "    print(f'      Decimated mesh saved in {decimated_path}')\n",
    "    \n",
    "saved_meshes = [stl_to_vtk(f) for f in saved_meshes]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "saved_meshes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Deformetrica"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "template_path = saved_meshes[0]\n",
    "dataset_paths = saved_meshes[1:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import deformetrica as dfca\n",
    "\n",
    "iteration_status_dictionaries = []\n",
    "\n",
    "def estimator_callback(status_dict):\n",
    "    iteration_status_dictionaries.append(status_dict)\n",
    "    return True\n",
    "\n",
    "# instantiate a Deformetrica object\n",
    "deformetrica = dfca.Deformetrica(output_dir='output', verbosity='INFO')\n",
    "\n",
    "dataset_specifications = {\n",
    "    'dataset_filenames': [[{'skull': f}] for f in dataset_paths],\n",
    "    'subject_ids': [os.path.splitext(os.path.split(f)[1])[0] for f in dataset_paths],\n",
    "}\n",
    "template_specifications = {\n",
    "    'skull': {'deformable_object_type': 'SurfaceMesh',\n",
    "              'kernel_type': 'torch', 'kernel_width': 20.0,\n",
    "              'noise_std': 10.0,\n",
    "              'filename': template_path,\n",
    "              'attachment_type': 'current'}\n",
    "}\n",
    "estimator_options={'optimization_method_type': 'GradientAscent', 'initial_step_size': 1.,\n",
    "                   'max_iterations': 25, 'max_line_search_iterations': 10, 'callback': estimator_callback}\n",
    "\n",
    "# perform a deterministic atlas estimation\n",
    "model = deformetrica.estimate_deterministic_atlas(template_specifications, dataset_specifications,\n",
    "                                                estimator_options=estimator_options,\n",
    "                                                model_options={'deformation_kernel_type': 'torch', 'deformation_kernel_width': 40.0, 'dtype': 'float32'})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decimating meshes...\n",
      "  Input folder: /home/fmatzkin/Code/datasets/cq500/converted/selected/preprocessed_ct_to_skull/test\n",
      "  Found 4 meshes\n",
      "    [1/4] Input mesh: CQ500-CT-54_CT Thin Plain.stl\n",
      "      Decimated mesh saved in /home/fmatzkin/Code/datasets/cq500/converted/selected/preprocessed_ct_to_skull/test/CQ500-CT-54_CT Thin Plain_decimated_0perc_3312points.stl\n",
      "    [2/4] Input mesh: CQ500-CT-182_CT PRE CONTRAST THIN.stl\n",
      "      Decimated mesh saved in /home/fmatzkin/Code/datasets/cq500/converted/selected/preprocessed_ct_to_skull/test/CQ500-CT-182_CT PRE CONTRAST THIN_decimated_0perc_3507points.stl\n",
      "    [3/4] Input mesh: CQ500-CT-405_CT Thin Plain.stl\n",
      "      Decimated mesh saved in /home/fmatzkin/Code/datasets/cq500/converted/selected/preprocessed_ct_to_skull/test/CQ500-CT-405_CT Thin Plain_decimated_0perc_3425points.stl\n",
      "    [4/4] Input mesh: CQ500-CT-133_CT Plain 3mm.stl\n",
      "      Decimated mesh saved in /home/fmatzkin/Code/datasets/cq500/converted/selected/preprocessed_ct_to_skull/test/CQ500-CT-133_CT Plain 3mm_decimated_0perc_3308points.stl\n"
     ]
    }
   ],
   "source": [
    "import vedo\n",
    "\n",
    "print('Decimating meshes...')\n",
    "decimate_percent = 0.005\n",
    "\n",
    "meshes_folder = eu('~/Code/datasets/cq500/converted/selected/preprocessed_ct_to_skull/test')\n",
    "print( f'  Input folder: {meshes_folder}')\n",
    "meshes_paths = [os.path.join(meshes_folder, f) for f in os.listdir(meshes_folder) if f.endswith('.stl') and 'decimated' not in f]\n",
    "saved_meshes = []\n",
    "print(f'  Found {len(meshes_paths)} meshes')\n",
    "for i, mesh in enumerate(meshes_paths):\n",
    "    print(f'    [{i+1}/{len(meshes_paths)}] Input mesh: {os.path.split(mesh)[1]}')\n",
    "    v_mesh = vedo.Mesh(mesh).decimate(decimate_percent)\n",
    "    decimated_path = mesh.replace('.stl', f'_decimated_{int(decimate_percent*100)}perc_{v_mesh.points().shape[0]}points.stl')\n",
    "    v_mesh.write(decimated_path)\n",
    "    saved_meshes.append(decimated_path)\n",
    "    print(f'      Decimated mesh saved in {decimated_path}')\n",
    "    \n",
    "saved_meshes = [stl_to_vtk(f) for f in saved_meshes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/fmatzkin/Code/datasets/cq500/converted/selected/preprocessed_ct_to_skull/test/CQ500-CT-54_CT Thin Plain_decimated_0perc_3312points.vtk',\n",
       " '/home/fmatzkin/Code/datasets/cq500/converted/selected/preprocessed_ct_to_skull/test/CQ500-CT-182_CT PRE CONTRAST THIN_decimated_0perc_3507points.vtk',\n",
       " '/home/fmatzkin/Code/datasets/cq500/converted/selected/preprocessed_ct_to_skull/test/CQ500-CT-405_CT Thin Plain_decimated_0perc_3425points.vtk',\n",
       " '/home/fmatzkin/Code/datasets/cq500/converted/selected/preprocessed_ct_to_skull/test/CQ500-CT-133_CT Plain 3mm_decimated_0perc_3308points.vtk']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_meshes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Deformetrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "template_path = saved_meshes[0]\n",
    "dataset_paths = saved_meshes[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logger has been set to: INFO\n",
      ">> No initial CP spacing given: using diffeo kernel width of 40.0\n",
      "OMP_NUM_THREADS found in environment variables. Using value OMP_NUM_THREADS=4\n",
      "context has already been set\n",
      ">> No specified state-file. By default, Deformetrica state will by saved in file: output/deformetrica-state.p.\n",
      ">> Set of 80 control points defined.\n",
      ">> Momenta initialized to zero, for 3 subjects.\n",
      ">> Started estimator: GradientAscent\n",
      "------------------------------------- Iteration: 0 -------------------------------------\n",
      ">> Log-likelihood = -1.675E+05 \t [ attachment = -1.675E+05 ; regularity = 0.000E+00 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t1.545E-05   and   6.471E+04 \t[ landmark_points ]\n",
      "\t\t1.183E-04   and   8.457E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 1 -------------------------------------\n",
      ">> Log-likelihood = -1.589E+05 \t [ attachment = -1.589E+05 ; regularity = -3.070E+00 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t2.318E-05   and   6.003E+04 \t[ landmark_points ]\n",
      "\t\t1.774E-04   and   7.852E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 2 -------------------------------------\n",
      ">> Log-likelihood = -1.479E+05 \t [ attachment = -1.479E+05 ; regularity = -1.750E+01 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t3.477E-05   and   5.373E+04 \t[ landmark_points ]\n",
      "\t\t2.661E-04   and   7.023E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 3 -------------------------------------\n",
      ">> Log-likelihood = -1.350E+05 \t [ attachment = -1.350E+05 ; regularity = -5.507E+01 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t5.216E-05   and   4.599E+04 \t[ landmark_points ]\n",
      "\t\t3.991E-04   and   5.969E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 4 -------------------------------------\n",
      ">> Log-likelihood = -1.215E+05 \t [ attachment = -1.214E+05 ; regularity = -1.318E+02 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t7.823E-05   and   3.790E+04 \t[ landmark_points ]\n",
      "\t\t5.986E-04   and   4.780E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 5 -------------------------------------\n",
      ">> Log-likelihood = -1.089E+05 \t [ attachment = -1.086E+05 ; regularity = -2.622E+02 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t1.174E-04   and   3.096E+04 \t[ landmark_points ]\n",
      "\t\t8.980E-04   and   3.630E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 6 -------------------------------------\n",
      ">> Log-likelihood = -9.800E+04 \t [ attachment = -9.755E+04 ; regularity = -4.496E+02 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t1.760E-04   and   2.541E+04 \t[ landmark_points ]\n",
      "\t\t1.347E-03   and   2.668E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 7 -------------------------------------\n",
      ">> Log-likelihood = -8.904E+04 \t [ attachment = -8.835E+04 ; regularity = -6.846E+02 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t2.640E-04   and   2.053E+04 \t[ landmark_points ]\n",
      "\t\t2.020E-03   and   1.969E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 8 -------------------------------------\n",
      ">> Log-likelihood = -8.135E+04 \t [ attachment = -8.039E+04 ; regularity = -9.552E+02 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t3.961E-04   and   1.643E+04 \t[ landmark_points ]\n",
      "\t\t3.031E-03   and   1.520E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 9 -------------------------------------\n",
      ">> Log-likelihood = -7.416E+04 \t [ attachment = -7.290E+04 ; regularity = -1.265E+03 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t5.941E-04   and   1.301E+04 \t[ landmark_points ]\n",
      "\t\t4.546E-03   and   1.220E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 10 -------------------------------------\n",
      ">> Log-likelihood = -6.747E+04 \t [ attachment = -6.579E+04 ; regularity = -1.671E+03 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t8.911E-04   and   1.267E+04 \t[ landmark_points ]\n",
      "\t\t6.819E-03   and   1.301E+03 \t[ momenta ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t4.456E-04   and   1.267E+04 \t[ landmark_points ]\n",
      "\t\t3.409E-03   and   1.301E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 11 -------------------------------------\n",
      ">> Log-likelihood = -6.595E+04 \t [ attachment = -6.419E+04 ; regularity = -1.761E+03 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t4.456E-04   and   1.626E+04 \t[ landmark_points ]\n",
      "\t\t1.705E-03   and   1.853E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 12 -------------------------------------\n",
      ">> Log-likelihood = -6.422E+04 \t [ attachment = -6.238E+04 ; regularity = -1.841E+03 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t4.456E-04   and   1.401E+04 \t[ landmark_points ]\n",
      "\t\t8.524E-04   and   1.333E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 13 -------------------------------------\n",
      ">> Log-likelihood = -6.289E+04 \t [ attachment = -6.102E+04 ; regularity = -1.875E+03 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t6.683E-04   and   1.069E+04 \t[ landmark_points ]\n",
      "\t\t1.279E-03   and   1.142E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 14 -------------------------------------\n",
      ">> Log-likelihood = -6.165E+04 \t [ attachment = -5.968E+04 ; regularity = -1.975E+03 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t1.003E-03   and   1.539E+04 \t[ landmark_points ]\n",
      "\t\t1.918E-03   and   1.448E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 15 -------------------------------------\n",
      ">> Log-likelihood = -6.089E+04 \t [ attachment = -5.889E+04 ; regularity = -2.007E+03 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t1.003E-03   and   2.181E+04 \t[ landmark_points ]\n",
      "\t\t9.589E-04   and   2.138E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 16 -------------------------------------\n",
      ">> Log-likelihood = -5.958E+04 \t [ attachment = -5.753E+04 ; regularity = -2.052E+03 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t1.003E-03   and   2.108E+04 \t[ landmark_points ]\n",
      "\t\t4.795E-04   and   1.856E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 17 -------------------------------------\n",
      ">> Log-likelihood = -5.837E+04 \t [ attachment = -5.631E+04 ; regularity = -2.062E+03 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t1.504E-03   and   1.898E+04 \t[ landmark_points ]\n",
      "\t\t7.192E-04   and   1.847E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 18 -------------------------------------\n",
      ">> Log-likelihood = -5.741E+04 \t [ attachment = -5.529E+04 ; regularity = -2.125E+03 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t7.519E-04   and   1.899E+04 \t[ landmark_points ]\n",
      "\t\t7.192E-04   and   1.723E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 19 -------------------------------------\n",
      ">> Log-likelihood = -5.651E+04 \t [ attachment = -5.437E+04 ; regularity = -2.137E+03 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t1.128E-03   and   1.742E+04 \t[ landmark_points ]\n",
      "\t\t1.079E-03   and   1.731E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 20 -------------------------------------\n",
      ">> Log-likelihood = -5.594E+04 \t [ attachment = -5.376E+04 ; regularity = -2.180E+03 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t1.128E-03   and   2.123E+04 \t[ landmark_points ]\n",
      "\t\t5.394E-04   and   1.875E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 21 -------------------------------------\n",
      ">> Log-likelihood = -5.557E+04 \t [ attachment = -5.338E+04 ; regularity = -2.186E+03 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t1.692E-03   and   2.439E+04 \t[ landmark_points ]\n",
      "\t\t8.091E-04   and   2.306E+03 \t[ momenta ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t8.459E-04   and   2.439E+04 \t[ landmark_points ]\n",
      "\t\t4.045E-04   and   2.306E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 22 -------------------------------------\n",
      ">> Log-likelihood = -5.403E+04 \t [ attachment = -5.181E+04 ; regularity = -2.222E+03 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t1.269E-03   and   1.682E+04 \t[ landmark_points ]\n",
      "\t\t6.068E-04   and   1.503E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 23 -------------------------------------\n",
      ">> Log-likelihood = -5.310E+04 \t [ attachment = -5.087E+04 ; regularity = -2.232E+03 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t6.344E-04   and   1.079E+04 \t[ landmark_points ]\n",
      "\t\t6.068E-04   and   1.159E+03 \t[ momenta ]\n",
      "------------------------------------- Iteration: 24 -------------------------------------\n",
      ">> Log-likelihood = -5.242E+04 \t [ attachment = -5.015E+04 ; regularity = -2.269E+03 ]\n",
      ">> Step size and gradient norm: \n",
      "\t\t9.516E-04   and   8.698E+03 \t[ landmark_points ]\n",
      "\t\t9.102E-04   and   8.475E+02 \t[ momenta ]\n",
      "------------------------------------- Iteration: 25 -------------------------------------\n",
      ">> Log-likelihood = -5.188E+04 \t [ attachment = -4.959E+04 ; regularity = -2.296E+03 ]\n",
      ">> Estimation took: 01 minutes and 59 seconds\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import deformetrica as dfca\n",
    "\n",
    "iteration_status_dictionaries = []\n",
    "\n",
    "def estimator_callback(status_dict):\n",
    "    iteration_status_dictionaries.append(status_dict)\n",
    "    return True\n",
    "\n",
    "# instantiate a Deformetrica object\n",
    "deformetrica = dfca.Deformetrica(output_dir='output', verbosity='INFO')\n",
    "\n",
    "dataset_specifications = {\n",
    "    'dataset_filenames': [[{'skull': f}] for f in dataset_paths],\n",
    "    'subject_ids': [os.path.splitext(os.path.split(f)[1])[0] for f in dataset_paths],\n",
    "}\n",
    "template_specifications = {\n",
    "    'skull': {'deformable_object_type': 'SurfaceMesh',\n",
    "              'kernel_type': 'torch', 'kernel_width': 20.0,\n",
    "              'noise_std': 10.0,\n",
    "              'filename': template_path,\n",
    "              'attachment_type': 'current'}\n",
    "}\n",
    "estimator_options={'optimization_method_type': 'GradientAscent', 'initial_step_size': 1.,\n",
    "                   'max_iterations': 25, 'max_line_search_iterations': 10, 'callback': estimator_callback}\n",
    "\n",
    "# perform a deterministic atlas estimation\n",
    "model = deformetrica.estimate_deterministic_atlas(template_specifications, dataset_specifications,\n",
    "                                                estimator_options=estimator_options,\n",
    "                                                model_options={'deformation_kernel_type': 'torch', 'deformation_kernel_width': 40.0, 'dtype': 'float32'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msr",
   "language": "python",
   "name": "msr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "159c917228f05416d9b819fe32ed20dc8363f68fb18cb83ee7ae4737bd8f0b32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}